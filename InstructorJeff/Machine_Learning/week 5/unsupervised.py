#UNSUPERVISED LEARNING:
# Unsupervised learning is a type of machine learning that deals with unlabeled data.
# unstructured data - uses pattern recognition to find structure in data.

"""
CHARACTERISTICS OF UNSUPERVISED LEARNING:
1. No labeled data: Unsupervised learning algorithms work with data that does not have predefined labels or categories.
2. Pattern discovery: The primary goal is to discover patterns, relationships, or structures within the
    data.
3. Clustering and association: Common tasks include clustering (grouping similar data points) and association (finding
    relationships between variables).


No labelled data
Used for Exploratory Data Analysis (EDA)
Can handle large datasets
"""

#TECHNIQUES of UNSUPERVISED LEARNING:
"""
1. Clustering: Grouping similar data points together based on their features.
  
  ALGORITHMS OF CLUSTERING:
   - K-Means Clustering: Partitions data into K clusters based on feature similarity.
   - Hierarchical Clustering: Builds a tree-like structure of clusters based on distance metrics.
   - DBSCAN: Density-based Sparial clustering that identifies clusters of varying shapes and sizes.
"""

#ADVANTAGES OF UNSUPERVISED LEARNING:
"""
1. No need for labeled data: Unsupervised learning can work with raw, unlabeled data, making it easier to apply in many scenarios.
2. Discover hidden patterns: It can reveal underlying structures and relationships in the data that may not
    be immediately apparent.
3. Scalability: Unsupervised learning algorithms can handle large datasets efficiently, making them suitable for big data applications.
4. Versatility: It can be applied to various types of data, including text, images, and numerical data, making it a versatile tool for data analysis.
5. Dimensionality reduction: Techniques like PCA (Principal Component Analysis) can reduce the number of features in a dataset while preserving important information, making it easier to visualize and analyze data.
6. Anomaly detection: Unsupervised learning can be used to identify unusual patterns or outliers in data, which can be valuable for fraud detection, network security, and quality control.
7. Feature extraction: It can automatically extract relevant features from raw data, reducing the need for
    manual feature engineering.
8. Data preprocessing: Unsupervised learning can be used to preprocess data by identifying and removing noise or irrelevant features, improving the quality of the data for subsequent analysis.
9. Data compression: Techniques like autoencoders can compress data while retaining important information, making
"""

#Example one: Real world problem
""""
Using K-means clustering
Cluster customers based on their annual income and spending.
"""

