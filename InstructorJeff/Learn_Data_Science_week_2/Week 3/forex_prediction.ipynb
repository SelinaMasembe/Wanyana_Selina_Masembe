{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df82696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forex Prediction Data Analysis\n",
    "\"\"\"\n",
    "OBJECTIVES\n",
    "1.Load and process the data set\n",
    "2.Inspect the data for empty values, wrong data, types, wrong formats, duplicates and outliners\n",
    "3.Analyze the data to find patterns and relationships (correlations)\n",
    "4.Visualize the data(graphs) to understand trends and distributions [in EUR/USD exchange rate movements for our dataset]\n",
    "5.Evaluate the model performance using appropriate metrics.\n",
    "6.Save the cleaned and processed data for future use.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819b5c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Predicted_Close</th>\n",
       "      <th>Currency_Pair</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>1.18727</td>\n",
       "      <td>1.92461</td>\n",
       "      <td>0.85312</td>\n",
       "      <td>1.18154</td>\n",
       "      <td>2201</td>\n",
       "      <td>1.22984</td>\n",
       "      <td>EUR/USD</td>\n",
       "      <td>Hold</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>1.47536</td>\n",
       "      <td>1.82881</td>\n",
       "      <td>0.54067</td>\n",
       "      <td>1.32296</td>\n",
       "      <td>error</td>\n",
       "      <td>1.03797</td>\n",
       "      <td>EUR/USD</td>\n",
       "      <td>Sell</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>1.36600</td>\n",
       "      <td>1.78415</td>\n",
       "      <td>0.54242</td>\n",
       "      <td>1.28539</td>\n",
       "      <td>4420</td>\n",
       "      <td>1.03888</td>\n",
       "      <td>EUR/USD</td>\n",
       "      <td>Sell</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>1.29933</td>\n",
       "      <td>1.54684</td>\n",
       "      <td>0.99332</td>\n",
       "      <td>1.17805</td>\n",
       "      <td>4079</td>\n",
       "      <td>1.00117</td>\n",
       "      <td>EUR/USD</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>1.07801</td>\n",
       "      <td>1.68386</td>\n",
       "      <td>0.68714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1832</td>\n",
       "      <td>1.48385</td>\n",
       "      <td>EUR/USD</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Open     High      Low    Close Volume  Predicted_Close  \\\n",
       "0  2024-01-01  1.18727  1.92461  0.85312  1.18154   2201          1.22984   \n",
       "1  2024-01-02  1.47536  1.82881  0.54067  1.32296  error          1.03797   \n",
       "2  2024-01-03  1.36600  1.78415  0.54242  1.28539   4420          1.03888   \n",
       "3  2024-01-04  1.29933  1.54684  0.99332  1.17805   4079          1.00117   \n",
       "4  2024-01-05  1.07801  1.68386  0.68714      NaN   1832          1.48385   \n",
       "\n",
       "  Currency_Pair Signal  Confidence  \n",
       "0       EUR/USD   Hold        0.90  \n",
       "1       EUR/USD   Sell         NaN  \n",
       "2       EUR/USD   Sell         NaN  \n",
       "3       EUR/USD   Sell        0.64  \n",
       "4       EUR/USD   Sell        0.68  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv('forex_predictions_data.csv')\n",
    "#first 5 rows\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419ea4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Predicted_Close</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>224.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.239946</td>\n",
       "      <td>1.753113</td>\n",
       "      <td>0.750030</td>\n",
       "      <td>1.245072</td>\n",
       "      <td>1.250415</td>\n",
       "      <td>0.756468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.148956</td>\n",
       "      <td>0.147816</td>\n",
       "      <td>0.150434</td>\n",
       "      <td>0.140594</td>\n",
       "      <td>0.156102</td>\n",
       "      <td>0.135125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.002530</td>\n",
       "      <td>1.505420</td>\n",
       "      <td>0.505680</td>\n",
       "      <td>1.002320</td>\n",
       "      <td>1.000120</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.111860</td>\n",
       "      <td>1.638832</td>\n",
       "      <td>0.614320</td>\n",
       "      <td>1.122535</td>\n",
       "      <td>1.115280</td>\n",
       "      <td>0.652500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.248105</td>\n",
       "      <td>1.763400</td>\n",
       "      <td>0.746310</td>\n",
       "      <td>1.235910</td>\n",
       "      <td>1.259605</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.365100</td>\n",
       "      <td>1.877682</td>\n",
       "      <td>0.877570</td>\n",
       "      <td>1.368805</td>\n",
       "      <td>1.392158</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.493440</td>\n",
       "      <td>1.995250</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.498440</td>\n",
       "      <td>1.499680</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open        High         Low       Close  Predicted_Close  \\\n",
       "count  224.000000  220.000000  225.000000  212.000000       222.000000   \n",
       "mean     1.239946    1.753113    0.750030    1.245072         1.250415   \n",
       "std      0.148956    0.147816    0.150434    0.140594         0.156102   \n",
       "min      1.002530    1.505420    0.505680    1.002320         1.000120   \n",
       "25%      1.111860    1.638832    0.614320    1.122535         1.115280   \n",
       "50%      1.248105    1.763400    0.746310    1.235910         1.259605   \n",
       "75%      1.365100    1.877682    0.877570    1.368805         1.392158   \n",
       "max      1.493440    1.995250    0.999860    1.498440         1.499680   \n",
       "\n",
       "       Confidence  \n",
       "count  218.000000  \n",
       "mean     0.756468  \n",
       "std      0.135125  \n",
       "min      0.500000  \n",
       "25%      0.652500  \n",
       "50%      0.760000  \n",
       "75%      0.870000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de60972e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the shape of the data-number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e734d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                3\n",
      "Open                5\n",
      "High                9\n",
      "Low                 4\n",
      "Close              17\n",
      "Volume              3\n",
      "Predicted_Close     7\n",
      "Currency_Pair       0\n",
      "Signal              2\n",
      "Confidence         11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for missing values or null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after handling :\n",
      "Date                 1\n",
      "Open                 0\n",
      "High                 0\n",
      "Low                  0\n",
      "Close                0\n",
      "Volume               0\n",
      "Predicted_Close      0\n",
      "Currency_Pair        0\n",
      "Signal             217\n",
      "Confidence           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#handling the missing values\n",
    "\n",
    "#fill empty values with median, for numeric columns\n",
    "\n",
    "#an array of numeric columns\n",
    "numeric_cols = ['Open','High','Low','Close','Volume','Predicted_Close','Confidence']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        \n",
    "        #this makes it easy to get the median for the cells with numbers and fill the empty ones with a value.\n",
    "        df[col] = pd.to_numeric(df[col],errors='coerce') #Convert to numeric,and anywhere else without a number coerce it with NaN\n",
    "        \n",
    "        #fillna with fillna using median\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "\n",
    "\n",
    "#for values of a column in categories or [non-numeric],use can use the MODAL VALUE for empty cells.\n",
    "categorical_cols =['Signal']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "        #fill NaN with mode\n",
    "        # Check if mode exists before filling NaN to avoid KeyError\n",
    "        mode_series = df[col].mode()\n",
    "        if not mode_series.empty:\n",
    "            df[col] = df[col].fillna(mode_series[0])\n",
    "        else:\n",
    "            # If mode is empty, fill with a placeholder or leave as NaN\n",
    "            df[col] = df[col]\n",
    "        \n",
    "#check again for missing values.\n",
    "print(\"Missing values after handling :\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8557f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data in wrong format\n",
    "\n",
    "#Convert 'Date' to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "#handle volume column with errors\n",
    "#1.First convert to numeric\n",
    "df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')\n",
    "#2.fill all the NaN with the median\n",
    "df['Volume'] = df['Volume'].fillna(df['Volume'].median())\n",
    "\n",
    "#handle confidence column\n",
    "df['Confidence'] = pd.to_numeric(df['Confidence'], errors='coerce')\n",
    "#2.fill all the NaN with the median\n",
    "df['Confidence'] = df['Confidence'].fillna(df['Confidence'].median())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fff7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrong data types\n",
    "price_cols =['Open','High','Low','Close','Predicted_Close']\n",
    "\n",
    "#deviations beyond +3 are outliers - use standard devition to remove them.\n",
    "for col in price_cols:\n",
    "    if col in df.columns:\n",
    "        #remove outliers (beyond 3 standard deviations)\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        df[col] =np.where((df[col]<mean-3*std) | (df[col]>mean+3*std),np.nan, df[col])\n",
    "        #after removing the outliers fill them with median\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f02eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  10\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicates - Number of duplicate rows\n",
    "print(\"Number of duplicate rows: \",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7c5b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing duplicates: 219\n"
     ]
    }
   ],
   "source": [
    "#remove duplicates - use drop\n",
    "df =df.drop_duplicates()\n",
    "print(\"Number of rows after removing duplicates:\",df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e0e78b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate dates: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(217, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Duplicate dates are handled differently\n",
    "print(\"Number of duplicate dates:\",df['Date'].duplicated().sum())\n",
    "#Remove duplicate dates\n",
    "df =df.drop_duplicates(subset=['Date'], keep ='first')\n",
    "#shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cdfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis\n",
    "# calculate correlation matrix\n",
    "corr_matrix = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Predicted_Close', 'Confidence']].corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, center=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33431fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted Close Prices\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['Date'], df['Close'], label='Actual Close Price', color='blue')\n",
    "plt.plot(df['Date'], df['Predicted_Close'], label='Predicted Close Price', color='orange')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Actual vs Predicted Close Prices')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Signal Performance Analysis\n",
    "df['Prediction_Error'] = abs(df['Close'] - df['Predicted_Close'])\n",
    "\n",
    "# Analyze error by signal type\n",
    "signal_error = df.groupby('Signal')['Prediction_Error'].mean()\n",
    "signal_confidence = df.groupby('Signal')['Confidence'].mean()\n",
    "# Plotting the average prediction error by signal type\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "signal_error.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Prediction Error by Signal Type')\n",
    "plt.xlabel('Signal Type')\n",
    "\n",
    "# Plotting the average confidence by signal type\n",
    "plt.subplot(1, 2, 2)\n",
    "signal_confidence.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Average Confidence by Signal Type')\n",
    "plt.xlabel('SignalÂ Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatility analysis - shows when it is high and when it low to know when to trade.\n",
    "#Volatility - measure of how prices keep changing\n",
    "#we can look at daily returns/range\n",
    "# Calculate daily returns\n",
    "df['Daily_Range'] = df['High']-df['Low']\n",
    "# Plot volatility over time\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['Date'], df['Daily_Range'], label='Daily Range', color='purple')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily Range')\n",
    "plt.title('Volatility Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd05fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key findings\n",
    "# 1. The dataset has been cleaned and preprocessed, with missing values handled and outliers removed.\n",
    "# 2. The correlation analysis shows strong relationships between the price columns, particularly between 'Open', 'High', 'Low', and 'Close'.\n",
    "# 3. The actual vs predicted close prices plot indicates that the model performs reasonably well, but there are some discrepancies.\n",
    "# 4. The signal performance analysis shows that the average prediction error varies by signal type, with 'Buy' signals generally having lower errors.\n",
    "# 5. The volatility analysis indicates fluctuations in the daily range, which can be useful for understanding market behavior.\n",
    "# 6. The cleaned and processed data is ready for further analysis or modeling.\n",
    "# Save the cleaned and processed data for future use\n",
    "\n",
    "\n",
    "# Price correlation analysis\n",
    "\n",
    "# Recemmendations for future work\n",
    "# 1. Model Improvement: Explore more advanced machine learning models or deep learning techniques to improve prediction accuracy.\n",
    "# 2. Feature Engineering: Create additional features that may capture market dynamics better, such as technical indicators (e.g., moving averages, RSI).\n",
    "# 3. Time Series Analysis: Implement time series analysis techniques to capture trends and seasonality in the data.\n",
    "# 4. Backtesting: Implement a backtesting framework to evaluate the performance of trading strategies based on the predictions.\n",
    "# 5. Real-time Data Integration: Consider integrating real-time data feeds to make predictions on live market conditions.\n",
    "# 6. Model Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
